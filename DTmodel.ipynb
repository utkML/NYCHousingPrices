{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as ske\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Pull in my data!\n",
    "train = pd.read_csv(\"~/Documents/utkml/NYCHousingPrices/train.csv\")\n",
    "test = pd.read_csv(\"~/Documents/utkml/NYCHousingPrices/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
      "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
      "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
      "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the data\n",
    "train.head()\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2014-10-13\n",
       "1       2014-12-09\n",
       "2       2015-02-25\n",
       "3       2014-12-09\n",
       "4       2015-02-18\n",
       "5       2014-05-12\n",
       "6       2014-06-27\n",
       "7       2015-01-15\n",
       "8       2015-04-15\n",
       "9       2015-03-12\n",
       "10      2015-04-03\n",
       "11      2014-05-27\n",
       "12      2014-05-28\n",
       "13      2014-10-07\n",
       "14      2015-03-12\n",
       "15      2015-01-24\n",
       "16      2014-07-31\n",
       "17      2014-05-29\n",
       "18      2014-12-05\n",
       "19      2015-04-24\n",
       "20      2014-05-14\n",
       "21      2014-08-26\n",
       "22      2014-07-03\n",
       "23      2014-05-16\n",
       "24      2014-11-20\n",
       "25      2014-11-03\n",
       "26      2014-06-26\n",
       "27      2014-12-01\n",
       "28      2014-06-24\n",
       "29      2015-03-02\n",
       "           ...    \n",
       "17260   2014-05-27\n",
       "17261   2014-07-29\n",
       "17262   2015-03-06\n",
       "17263   2015-02-05\n",
       "17264   2014-07-08\n",
       "17265   2014-10-28\n",
       "17266   2014-09-23\n",
       "17267   2014-10-25\n",
       "17268   2015-05-08\n",
       "17269   2015-01-23\n",
       "17270   2014-05-27\n",
       "17271   2014-10-23\n",
       "17272   2015-02-26\n",
       "17273   2015-03-30\n",
       "17274   2014-11-17\n",
       "17275   2014-09-26\n",
       "17276   2014-11-26\n",
       "17277   2015-02-11\n",
       "17278   2014-08-13\n",
       "17279   2014-06-24\n",
       "17280   2014-08-13\n",
       "17281   2015-02-27\n",
       "17282   2015-03-18\n",
       "17283   2015-02-19\n",
       "17284   2015-03-04\n",
       "17285   2014-11-06\n",
       "17286   2014-06-16\n",
       "17287   2014-05-07\n",
       "17288   2014-07-25\n",
       "17289   2015-01-28\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['date'] = pd.to_datetime(train['date'], format='%Y-%m-%d')\n",
    "train['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "# --------\n",
    "\n",
    "train.drop(['id'], axis=1, inplace=True)\n",
    "train.drop(['date'], axis=1, inplace=True)\n",
    "\n",
    "# Any missing values?\n",
    "train.isnull().values.any()\n",
    "\n",
    "def preprocess(df):\n",
    "    \"\"\"\n",
    "    Starter kit for preprocessing data. \n",
    "    \n",
    "    - Right now this just one hot encodes\n",
    "      the grade feature.\n",
    "    \"\"\"\n",
    "    processed_df = df.copy()\n",
    "    le = ske.preprocessing.LabelEncoder()\n",
    "    processed_df.Sex = le.fit_transform(processed_df.grade)\n",
    "    return processed_df\n",
    "\n",
    "processed_train = preprocess(train)\n",
    "processed_test = preprocess(test)\n",
    "\n",
    "# We are trying to predict Price, so I need to drop it in X. I'll make Y that has only the Prices.\n",
    "y = processed_train['price'].values\n",
    "X = processed_train.drop(['price'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has shape (13832, 18)\n",
      "y_train has shape (13832,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = ske.cross_validation.train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "print(\"X_train has shape {}\".format(X_train.shape))\n",
    "print(\"y_train has shape {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = RandomForestRegressor()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get predictions on the validation set\n",
    "preds = reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75809.064117023314"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not the error used in the competition, but hey.\n",
    "mean_absolute_error(y_pred=preds, y_true=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
